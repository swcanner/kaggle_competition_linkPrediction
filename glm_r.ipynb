{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/iupui-link-prediction/features.csv\n",
      "/kaggle/input/iupui-link-prediction/sample_submission.csv\n",
      "/kaggle/input/iupui-link-prediction/train_edges.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"/kaggle/input/iupui-link-prediction/train_edges.csv\";\n",
    "sample_sub = \"/kaggle/input/iupui-link-prediction/sample_submission.csv\"\n",
    "test_file = \"/kaggle/input/iupui-link-prediction/features.csv\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_index(G):\n",
    "    \n",
    "    s = sorted(G.nodes);\n",
    "    num_nodes = max(s)+1;\n",
    "    \n",
    "    #Store it into a matrix for self preservation\n",
    "    #num_nodes = G.number_of_nodes();\n",
    "    common_neigh = np.zeros((num_nodes,num_nodes));\n",
    "    salton = common_neigh.copy();\n",
    "    jaccard = common_neigh.copy();\n",
    "    sorensen = common_neigh.copy();\n",
    "    hub_promoted = common_neigh.copy();\n",
    "    hub_depressed = common_neigh.copy();\n",
    "    \n",
    "    for i in s:\n",
    "        if (i % 100 == 0):\n",
    "            print(i)\n",
    "        for j in s:\n",
    "            if (i != j):\n",
    "                deg_i = G.degree[i];\n",
    "                deg_j = G.degree[j];\n",
    "                min_deg = deg_i;\n",
    "                max_deg = deg_j;\n",
    "                if (deg_j < min_deg):\n",
    "                    min_deg = deg_j;\n",
    "                    max_deg = deg_i;\n",
    "\n",
    "                num_com = len(sorted(nx.common_neighbors(G,i,j)));\n",
    "                common_neigh[i,j] = num_com;\n",
    "\n",
    "                if (num_com > 0):\n",
    "                    salt = num_com / math.sqrt(deg_i * deg_j);\n",
    "                    jac = num_com / (deg_i + deg_j - num_com);\n",
    "                    sor = 2 * num_com / (deg_i + deg_j);\n",
    "                    hub_d = num_com / min_deg;\n",
    "                    hub_p = num_com / max_deg;\n",
    "\n",
    "                    salton[i,j] = salt;\n",
    "                    jaccard[i,j] = jac;\n",
    "                    sorensen[i,j] = sor;\n",
    "                    hub_promoted[i,j] = hub_p;\n",
    "                    hub_depressed[i,j] = hub_d;\n",
    "                \n",
    "    \n",
    "    return(common_neigh,salton,jaccard,sorensen,hub_promoted,hub_depressed);\n",
    "\n",
    "def calc_common_neigh(G):\n",
    "    #Store it into a matrix for self preservation\n",
    "    num_nodes = G.number_of_nodes();\n",
    "    common_neigh = np.zeros((num_nodes,num_nodes));\n",
    "    \n",
    "    for i in range(num_nodes):\n",
    "        if (i % 100 == 0):\n",
    "            print(i)\n",
    "        for j in range(num_nodes):\n",
    "            if (i != j):\n",
    "                num_com = len(sorted(nx.common_neighbors(G,i,j)));\n",
    "                common_neigh[i,j] = num_com\n",
    "    \n",
    "    return(common_neigh);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#Load the input files\n",
    "import csv\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "with open(train_file) as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in spamreader:\n",
    "        if row[1]=='1':\n",
    "            edge= row[0].split('-')\n",
    "            G.add_edge(int(edge[0]),int(edge[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2506\n"
     ]
    }
   ],
   "source": [
    "#Node info\n",
    "print(G.number_of_nodes());\n",
    "#nx.draw(G,node_size = 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next let's read in the possible edges we need to classify from the test file\n",
    "Gsub = nx.Graph()\n",
    "\n",
    "with open(sample_sub) as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in spamreader:\n",
    "        if row[1]=='1' or row[1]=='0':\n",
    "            edge= row[0].split('-')\n",
    "            Gsub.add_edge(int(edge[0]),int(edge[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187\n"
     ]
    }
   ],
   "source": [
    "#print(sorted(G.nodes))\n",
    "s = sorted(G.nodes);\n",
    "#print(s)\n",
    "a = 0;\n",
    "for i in range(len(s)-1):\n",
    "    if(s[i+1] - s[i] != 1):\n",
    "        a += 1;\n",
    "print(a)\n",
    "#print(G.degree[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "400\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n"
     ]
    }
   ],
   "source": [
    "#n = calc_common_neigh(G)\n",
    "com,salt,jac,sor,hub_p,hub_d = calc_index(G);\n",
    "\n",
    "#print(com,salt,jac,sor,hub_p,hub_d);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "400\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [2.         0.10166571 0.01538462 ... 0.01550388 0.66666667 1.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Now I need to make this into something that I can feed into a neural net like nothing\n",
    "num_nodes = max(s)+1;\n",
    "adj = nx.adjacency_matrix(G);\n",
    "adj = adj.todense();\n",
    "\n",
    "datum = np.zeros((num_nodes**2,7));\n",
    "\n",
    "for i in s:\n",
    "    if (i % 100 == 0):\n",
    "            print(i)\n",
    "    for j in s:\n",
    "        if (j > i):\n",
    "            ind = i*num_nodes+j;\n",
    "            datum[ind,0] = com[i,j];\n",
    "            datum[ind,1] = salt[i,j];\n",
    "            datum[ind,2] = jac[i,j];\n",
    "            datum[ind,3] = sor[i,j];\n",
    "            datum[ind,4] = hub_p[i,j];\n",
    "            datum[ind,5] = hub_d[i,j];\n",
    "            ind_i = s.index(i);\n",
    "            ind_j = s.index(j);\n",
    "            \n",
    "            datum[ind,6] = adj[ind_i,ind_j];\n",
    "        \n",
    "#remove the all zero rows\n",
    "#datum = datum[~np.all(datum == 0, axis=1)];\n",
    "#Append an all zero row\n",
    "#oof = np.zeros((1,7));\n",
    "#datum = np.append(datum,oof);\n",
    "datum = datum.reshape(-1,7);\n",
    "print(datum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datum = datum.reshape(-1,7)\n",
    "#print(datum)\n",
    "#Output the data to a csv for further analysis in Frickin R\n",
    "#Because I have to for the fricking HW assignment.\n",
    "df = pd.DataFrame(datum);\n",
    "df.to_csv(\"/kaggle/working/train_r.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2708\n"
     ]
    }
   ],
   "source": [
    "#print(G)\n",
    "#list(G.nodes)         \n",
    "#print(Gsub.nodes)\n",
    "# we need to add the nodes from the test data to training network (some are new nodes)\n",
    "G.add_nodes_from(Gsub.nodes)\n",
    "print(G.number_of_nodes());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is a simple algorithm to get you started...for each possible edge i-j in the test set\n",
    "# we will count the number of nodes in the training graph they have in common...if they have\n",
    "# one or more \"mutual friends\" then we will connect them (this will score about .67 acc on kaggle)\n",
    "with open('/kaggle/working/stupid_train.csv', 'w') as csvfile:\n",
    "    fieldnames = ['edge', 'label']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    with open(sample_sub) as csvfile2:\n",
    "        reader = csv.reader(csvfile2, delimiter=',')\n",
    "        for row in reader:\n",
    "            if row[1]=='1' or row[1]=='0':\n",
    "                edge= row[0].split('-')\n",
    "\n",
    "                i=int(edge[0])\n",
    "                j=int(edge[1])\n",
    "                \n",
    "                # here networkx has a common_neighbors function\n",
    "                num_com_neigh=len(sorted(nx.common_neighbors(G, i, j)))\n",
    "                y=0\n",
    "                #if num_com_neigh>0:\n",
    "                #    y=1\n",
    "\n",
    "                edg_out=str(i)+\"-\"+str(j)    \n",
    "                writer.writerow({'edge': edg_out, 'label': y})\n",
    "                #print(edg_out, num_com_neigh, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "[[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#Output the wanted stuff\n",
    "#Recalculate with the new stuff\n",
    "com,salt,jac,sor,hub_p,hub_d = calc_index(G);\n",
    "\n",
    "out_df = pd.read_csv(sample_sub);\n",
    "out_df = out_df.values;\n",
    "sz = np.shape(out_df);\n",
    "\n",
    "out_file = np.zeros((sz[0],6));\n",
    "for i in range(sz[0]):\n",
    "    edge= out_df[i,0];\n",
    "    edge = edge.split('-');\n",
    "    j = int(edge[0]);\n",
    "    k = int(edge[1]);\n",
    "    #print(j,k)\n",
    "    \n",
    "    out_file[i,0] = com[j,k];\n",
    "    out_file[i,1] = salt[j,k];\n",
    "    out_file[i,2] = jac[j,k];\n",
    "    out_file[i,3] = sor[j,k];\n",
    "    out_file[i,4] = hub_p[j,k];\n",
    "    out_file[i,5] = hub_d[j,k];\n",
    "\n",
    "print(out_file)\n",
    "#print(np.mean(out_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output the outfile\n",
    "out_file_df = pd.DataFrame(out_file);\n",
    "out_file_df.to_csv(\"/kaggle/working/test_r.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
